{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ilhom-Utkirov/NAS/blob/main/check_gpu2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czh4P947Ezc9",
        "outputId": "97264bee-c006-4858-c836-bbe46f9dcee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Olw7fWr17AEU",
        "outputId": "466f5580-757e-43f1-a229-cda499c9b89b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/mldl_projects2\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/mldl_projects2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7V31HqrXFTk",
        "outputId": "c609bdbb-2dba-4b92-fef7-6d945dc8a175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/mldl_projects2\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55CU0ebcm_Ed",
        "outputId": "957f608a-1881-403b-c174-a530c78cccd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34m'$'\u001b[0m/   \u001b[01;34mcoco\u001b[0m/   \u001b[01;34mvisualwakewords\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt3tehFELdSt",
        "outputId": "e9ac9feb-0090-421e-d75b-1b38c0a505cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'visualwakewords'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 79 (delta 1), reused 6 (delta 1), pack-reused 71\u001b[K\n",
            "Unpacking objects: 100% (79/79), 892.43 KiB | 836.00 KiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Mxbonn/visualwakewords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJjcFQwLE0mI",
        "outputId": "b62bc875-ba32-432d-e436-5d15eb5d0471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyvww\n",
            "  Downloading pyvww-0.1.1-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from pyvww) (2.0.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from pyvww) (0.15.2+cu118)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools->pyvww) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools->pyvww) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->pyvww) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision->pyvww) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->pyvww) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->pyvww) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->pyvww) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->pyvww) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->pyvww) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->pyvww) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->pyvww) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->pyvww) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->pyvww) (16.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->pyvww) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->pyvww) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->pyvww) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->pyvww) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools->pyvww) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision->pyvww) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision->pyvww) (1.3.0)\n",
            "Installing collected packages: pyvww\n",
            "Successfully installed pyvww-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyvww"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD3UDLxcCfd5",
        "outputId": "ea744966-4cd5-43c1-92ae-d07e6f7ad9fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pyvww\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import VisionDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.cuda.is_available()\n",
        "# True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHYIJY0uMBdM",
        "outputId": "313ce506-3bd8-4a27-b45f-a58b1f9c146f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bash: /content/drive/MyDrive/mldl_project2/visualwakewords/scripts/download_mscoco.sh: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!bash /content/drive/MyDrive/mldl_project2/visualwakewords/scripts/download_mscoco.sh /content/drive/MyDrive/mldl_project2/coco 2014\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGJHxMuBBWqt",
        "outputId": "d33ea923-3cbf-4df6-94e1-b937b95c97a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The folder is empty.\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "\n",
        "# folder_path = '/content/coco-dataset/all2014'  # Replace with the path to your folder\n",
        "\n",
        "# # List all files and directories in the folder\n",
        "# contents = os.listdir(folder_path)\n",
        "\n",
        "# # Check if the folder is empty\n",
        "# if len(contents) == 0:\n",
        "#     print(\"The folder is empty.\")\n",
        "# else:\n",
        "#     print(\"The folder is not empty.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKYejUiIMKP0"
      },
      "outputs": [],
      "source": [
        "TRAIN_ANNOTATIONS_FILE=\"/content/coco-dataset/annotations/instances_train2014.json\"\n",
        "VAL_ANNOTATIONS_FILE=\"/content/coco-dataset/annotations/instances_val2014.json\"\n",
        "DIR=\"/content/coco-dataset/annotations\"\n",
        "!python /content/drive/MyDrive/mldl_projects2/visualwakewords/scripts/create_coco_train_minival_split.py --train_annotations_file=\"/content/coco-dataset/annotations/instances_train2014.json\" --val_annotations_file=\"/content/coco-dataset/annotations/instances_val2014.json\" --output_dir=\"/content/coco-dataset/annotations\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zq5mrVzWxiR8"
      },
      "outputs": [],
      "source": [
        "# List all files in the folder\n",
        "# import os\n",
        "# import pandas as pd\n",
        "\n",
        "# files = os.listdir('/content/$/content/coco-dataset/annotations')\n",
        "\n",
        "# # Filter for image files\n",
        "# image_files = [file for file in files if file.endswith(('.jpg', '.jpeg', '.png', '.gif'))]\n",
        "\n",
        "# # Create a DataFrame to store the file names\n",
        "# df = pd.DataFrame({'File Name': image_files})\n",
        "# Display the DataFrame\n",
        "# print(df)\n",
        "# df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jD9AJgazaK-"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypBuowHDlfmp",
        "outputId": "f203c206-74c5-43e7-ee5b-d7eafb6f106c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco' -> '/content/drive/MyDrive/mldl/coco'\n",
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/all2014' -> '/content/drive/MyDrive/mldl/coco/all2014'\n",
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/all2014/val2014' -> '/content/drive/MyDrive/mldl/coco/all2014/val2014'\n",
            "cp: cannot access '/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/all2014/val2014': Input/output error\n",
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/all2014/train2014' -> '/content/drive/MyDrive/mldl/coco/all2014/train2014'\n",
            "cp: cannot access '/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/all2014/train2014': Input/output error\n",
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/annotations' -> '/content/drive/MyDrive/mldl/coco/annotations'\n",
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/annotations/instances_train2014.json' -> '/content/drive/MyDrive/mldl/coco/annotations/instances_train2014.json'\n",
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/annotations/instances_val2014.json' -> '/content/drive/MyDrive/mldl/coco/annotations/instances_val2014.json'\n",
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/annotations/person_keypoints_train2014.json' -> '/content/drive/MyDrive/mldl/coco/annotations/person_keypoints_train2014.json'\n",
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/annotations/person_keypoints_val2014.json' -> '/content/drive/MyDrive/mldl/coco/annotations/person_keypoints_val2014.json'\n",
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/annotations/captions_train2014.json' -> '/content/drive/MyDrive/mldl/coco/annotations/captions_train2014.json'\n",
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/annotations/captions_val2014.json' -> '/content/drive/MyDrive/mldl/coco/annotations/captions_val2014.json'\n",
            "'/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/.ipynb_checkpoints' -> '/content/drive/MyDrive/mldl/coco/.ipynb_checkpoints'\n"
          ]
        }
      ],
      "source": [
        "# %cp -av /content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco /content/drive/MyDrive/mldl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI-_JzzxqSyh",
        "outputId": "9c8d2492-fe0e-4804-df49-dd795bbedff2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "82783\n"
          ]
        }
      ],
      "source": [
        "import os, os.path\n",
        "\n",
        "# simple version for working with CWD\n",
        "# print len([name for name in os.listdir('.') if os.path.isfile(name)])\n",
        "\n",
        "#### check if folder is empty\n",
        "# path joining version for other paths\n",
        "DIR = '/content/drive/MyDrive/mldl/coco/all2014/train2014'\n",
        "print(len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcV0HkfnykJs",
        "outputId": "9bb701a2-480c-49f9-be26-eb57be07fcb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=9.92s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=2.81s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "import pyvww\n",
        "train_data = pyvww.pytorch.VisualWakeWordsClassification(root=\"/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/all2014\",\n",
        "                                                         annFile=\"/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/annotations/instances_train.json\")\n",
        "val_data = pyvww.pytorch.VisualWakeWordsClassification(root=\"/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/all2014/val2014\", annFile=\"/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/annotations/instances_val.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "f9TFu7LUIXPw",
        "outputId": "c5ea9fc4-c5da-40eb-9dba-506720ac431e"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0e7a13ebcf98>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyvww/pytorch/datasets.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ColabNotebooks/mldl_project_2023/coco/all2014/COCO_train2014_000000000036.jpg'"
          ]
        }
      ],
      "source": [
        "train_data[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVrQ-OWvUzaR",
        "outputId": "0df67ea0-1c03-4382-8567-7b00eed732e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/drive/MyDrive/mldl_project_2023/coco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0w5PtRHSIr6"
      },
      "outputs": [],
      "source": [
        "# Define your training and validation datasets\n",
        "train_dataset = VisualWakeWordsDataset(root='path/to/train/dataset', transform=transforms.ToTensor())\n",
        "val_dataset = VisualWakeWordsDataset(root='path/to/val/dataset', transform=transforms.ToTensor())\n",
        "\n",
        "# Define your training and validation dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eSwY0xhSCSy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# CNN\n",
        "class MyCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCNN, self).__init__()\n",
        "        # CNN architecture\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc = nn.Linear(32 * 8 * 8, 2)  # Adjust the output size based on your problem\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# 2 Random Search with Training-free metrics\n",
        "class RandomModel:\n",
        "    def __init__(self):\n",
        "        # random model configuration\n",
        "        self.model = MyCNN()\n",
        "\n",
        "    def get_model(self):\n",
        "        return self.model\n",
        "\n",
        "# 3: NASWOT function\n",
        "def NASWOT(net: nn.Module, inputs: torch.Tensor, targets: torch.Tensor, device: torch.device):\n",
        "    with torch.no_grad():\n",
        "        codes = []\n",
        "\n",
        "        def hook(self: nn.Module, m_input: torch.Tensor, m_output: torch.Tensor):\n",
        "            code = (m_output > 0).flatten(start_dim=1)\n",
        "            codes.append(code)\n",
        "\n",
        "        hooks = []\n",
        "        for m in net.modules():\n",
        "            if isinstance(m, nn.ReLU):\n",
        "                hooks.append(m.register_forward_hook(hook))\n",
        "\n",
        "        _ = net(inputs)\n",
        "\n",
        "        for h in hooks:\n",
        "            h.remove()\n",
        "\n",
        "        full_code = torch.cat(codes, dim=1)\n",
        "\n",
        "        # Fast Hamming distance matrix computation\n",
        "        del codes, _\n",
        "        full_code_float = full_code.float()\n",
        "        k = full_code_float @ full_code_float.t()\n",
        "        del full_code_float\n",
        "        not_full_code_float = torch.logical_not(full_code).float()\n",
        "        k += not_full_code_float @ not_full_code_float.t()\n",
        "        del not_full_code_float\n",
        "\n",
        "        return torch.slogdet(k).logabsdet.item() #return score\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "class VisualWakeWordsDataset(VisionDataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        super(VisualWakeWordsDataset, self).__init__(root, transform=transform)\n",
        "\n",
        "        # Load the dataset and process it here\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Retrieve and preprocess a single sample from the dataset\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of samples in the dataset\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "# Train and evaluate the models using Random Search with Training-free metrics\n",
        "best_model = None\n",
        "highest_score = -float('inf')\n",
        "\n",
        "for iteration in range(n_items):\n",
        "    model = RandomModel().get_model()\n",
        "    score = NASWOT(model, input)  # Replace 'input' with your own data\n",
        "    if score > highest_score:\n",
        "        best_model = model\n",
        "        highest_score = score\n",
        "\n",
        "# Evaluate the best model based on the given constraints\n",
        "params_count = sum(p.numel() for p in best_model.parameters())\n",
        "flops = compute_flops(best_model, input)  # Replace 'input' with your own data\n",
        "\n",
        "accuracy = evaluate_model(best_model, val_dataloader)  # Replace with your own evaluation method\n",
        "\n",
        "if params_count <= 2.5e6 and flops <= 2e8 and accuracy >= 80:\n",
        "    print(\"Best model satisfies the constraints!\")\n",
        "else:\n",
        "    print(\"No model found that satisfies the constraints.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}